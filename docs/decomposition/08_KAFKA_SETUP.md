# 08 - Apache Kafka Setup

**ĞŸÑ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹:** [07_API_GATEWAY.md](07_API_GATEWAY.md)  
**Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹:** [09_LOGGING_SERVICE_OVERVIEW.md](09_LOGGING_SERVICE_OVERVIEW.md)

---

## ğŸ¯ Ğ—Ğ°Ñ‡ĞµĞ¼ Ğ½ÑƒĞ¶ĞµĞ½ Kafka

**Apache Kafka** - ÑÑ‚Ğ¾ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ½Ğ°Ñ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹:

- **ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ¼ÑƒĞ½Ğ¸ĞºĞ°Ñ†Ğ¸Ñ** Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¼Ğ¸ĞºÑ€Ğ¾ÑĞµÑ€Ğ²Ğ¸ÑĞ°Ğ¼Ğ¸
- **Event Sourcing** - ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ²ÑĞµÑ… ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹
- **Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ½Ğ°Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ** - Ğ¼Ğ¸Ğ»Ğ»Ğ¸Ğ¾Ğ½Ñ‹ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ² ÑĞµĞºÑƒĞ½Ğ´Ñƒ
- **ĞĞ°Ğ´ĞµĞ¶Ğ½Ğ¾ÑÑ‚ÑŒ** - Ñ€ĞµĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¸ Ğ¿ĞµÑ€ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ
- **ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾ÑÑ‚ÑŒ** - Ğ³Ğ¾Ñ€Ğ¸Ğ·Ğ¾Ğ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

---

## ğŸ“Š ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Kafka Ğ² Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Producers                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Monolith  â”‚  Logging Service  â”‚  Analytics Service    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚                    â”‚
       â–¼              â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Apache Kafka                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Topic: logging-events        (3 partitions)            â”‚
â”‚  Topic: analytics-events      (3 partitions)            â”‚
â”‚  Topic: escalation-events     (2 partitions)            â”‚
â”‚  Topic: emr-sync-events       (2 partitions)            â”‚
â”‚  Topic: notification-events   (2 partitions)            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚                    â”‚
       â–¼              â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Consumers                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Logging Service  â”‚  Analytics Service  â”‚  Notification â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ³ Docker Compose ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ

Ğ£Ğ¶Ğµ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ² `docker-compose.yml` (ÑĞ¼. [04_DOCKER_SETUP.md](04_DOCKER_SETUP.md)):

```yaml
zookeeper:
  image: confluentinc/cp-zookeeper:7.5.0
  ports:
    - "2181:2181"
  environment:
    ZOOKEEPER_CLIENT_PORT: 2181
    ZOOKEEPER_TICK_TIME: 2000

kafka:
  image: confluentinc/cp-kafka:7.5.0
  ports:
    - "9092:9092"
    - "29092:29092"
  environment:
    KAFKA_BROKER_ID: 1
    KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
    KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
  depends_on:
    - zookeeper

kafka-ui:
  image: provectuslabs/kafka-ui:latest
  ports:
    - "8090:8080"
  environment:
    KAFKA_CLUSTERS_0_NAME: local
    KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
  depends_on:
    - kafka
```

---

## ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑĞº Kafka

```bash
# Ğ—Ğ°Ğ¿ÑƒÑĞº Zookeeper Ğ¸ Kafka
docker-compose up -d zookeeper kafka

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑ‚Ğ°Ñ‚ÑƒÑĞ°
docker-compose ps

# Ğ›Ğ¾Ğ³Ğ¸ Kafka
docker-compose logs -f kafka

# Ğ—Ğ°Ğ¿ÑƒÑĞº Kafka UI
docker-compose up -d kafka-ui
```

Kafka UI Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ Ğ¿Ğ¾ Ğ°Ğ´Ñ€ĞµÑÑƒ: http://localhost:8090

---

## ğŸ“ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ¿Ğ¸ĞºĞ¾Ğ²

### ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ

Kafka Ğ½Ğ°ÑÑ‚Ñ€Ğ¾ĞµĞ½ Ğ½Ğ° Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ¿Ğ¸ĞºĞ¾Ğ² (`KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"`).

### Ğ ÑƒÑ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ

```bash
# Ğ’Ğ¾Ğ¹Ñ‚Ğ¸ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Kafka
docker exec -it kafka bash

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ¿Ğ¸Ğº
kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic logging-events \
  --partitions 3 \
  --replication-factor 1

# Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ñ‚Ğ¾Ğ¿Ğ¸ĞºĞ¾Ğ²
kafka-topics --list --bootstrap-server localhost:9092

# ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ¿Ğ¸ĞºĞ°
kafka-topics --describe \
  --bootstrap-server localhost:9092 \
  --topic logging-events
```

### Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ²ÑĞµÑ… Ñ‚Ğ¾Ğ¿Ğ¸ĞºĞ¾Ğ²

Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ Ñ„Ğ°Ğ¹Ğ» `create-topics.sh`:

```bash
#!/bin/bash

KAFKA_CONTAINER="kafka"
BOOTSTRAP_SERVER="localhost:9092"

echo "Creating Kafka topics..."

# Logging events
docker exec $KAFKA_CONTAINER kafka-topics --create \
  --bootstrap-server $BOOTSTRAP_SERVER \
  --topic logging-events \
  --partitions 3 \
  --replication-factor 1 \
  --if-not-exists

# Analytics events
docker exec $KAFKA_CONTAINER kafka-topics --create \
  --bootstrap-server $BOOTSTRAP_SERVER \
  --topic analytics-events \
  --partitions 3 \
  --replication-factor 1 \
  --if-not-exists

# Escalation events
docker exec $KAFKA_CONTAINER kafka-topics --create \
  --bootstrap-server $BOOTSTRAP_SERVER \
  --topic escalation-events \
  --partitions 2 \
  --replication-factor 1 \
  --if-not-exists

# EMR sync events
docker exec $KAFKA_CONTAINER kafka-topics --create \
  --bootstrap-server $BOOTSTRAP_SERVER \
  --topic emr-sync-events \
  --partitions 2 \
  --replication-factor 1 \
  --if-not-exists

# Notification events
docker exec $KAFKA_CONTAINER kafka-topics --create \
  --bootstrap-server $BOOTSTRAP_SERVER \
  --topic notification-events \
  --partitions 2 \
  --replication-factor 1 \
  --if-not-exists

echo "Topics created successfully!"

# List all topics
docker exec $KAFKA_CONTAINER kafka-topics --list --bootstrap-server $BOOTSTRAP_SERVER
```

Ğ—Ğ°Ğ¿ÑƒÑĞº:

```bash
chmod +x create-topics.sh
./create-topics.sh
```

---

## ğŸ”§ ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Producer

### Maven Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ÑŒ

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
```

### KafkaProducerConfig.java

```java
package pain.management.config;

import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;
import org.springframework.kafka.support.serializer.JsonSerializer;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaProducerConfig {
    
    @Value("${spring.kafka.bootstrap-servers:localhost:9092}")
    private String bootstrapServers;
    
    @Bean
    public ProducerFactory<String, Object> producerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        config.put(ProducerConfig.ACKS_CONFIG, "1");
        config.put(ProducerConfig.RETRIES_CONFIG, 3);
        config.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 5);
        config.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
        return new DefaultKafkaProducerFactory<>(config);
    }
    
    @Bean
    public KafkaTemplate<String, Object> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
}
```

### ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ

```java
@Service
@RequiredArgsConstructor
public class EventPublisher {
    
    private final KafkaTemplate<String, Object> kafkaTemplate;
    
    public void publishLogEvent(LogEvent event) {
        kafkaTemplate.send("logging-events", event.getId(), event);
    }
}
```

---

## ğŸ”§ ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Consumer

### KafkaConsumerConfig.java

```java
package pain.management.config;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.listener.ContainerProperties;
import org.springframework.kafka.support.serializer.JsonDeserializer;

import java.util.HashMap;
import java.util.Map;

@EnableKafka
@Configuration
public class KafkaConsumerConfig {
    
    @Value("${spring.kafka.bootstrap-servers:localhost:9092}")
    private String bootstrapServers;
    
    @Value("${spring.kafka.consumer.group-id}")
    private String groupId;
    
    @Bean
    public ConsumerFactory<String, Object> consumerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        config.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
        config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        config.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
        config.put(JsonDeserializer.TRUSTED_PACKAGES, "*");
        return new DefaultKafkaConsumerFactory<>(config);
    }
    
    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = 
            new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        factory.setConcurrency(3);
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL);
        return factory;
    }
}
```

### ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ

```java
@Component
@RequiredArgsConstructor
@Slf4j
public class LogEventConsumer {
    
    private final LoggingService loggingService;
    
    @KafkaListener(
        topics = "logging-events",
        groupId = "${spring.kafka.consumer.group-id}"
    )
    public void consumeLogEvent(
            @Payload LogEvent event,
            @Header(KafkaHeaders.RECEIVED_PARTITION) int partition,
            @Header(KafkaHeaders.OFFSET) long offset,
            Acknowledgment acknowledgment
    ) {
        try {
            log.debug("Received event from partition {} offset {}", partition, offset);
            loggingService.processLogEvent(event);
            acknowledgment.acknowledge();
        } catch (Exception e) {
            log.error("Error processing event", e);
            // ĞĞµ acknowledge - ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ¾
        }
    }
}
```

---

## ğŸ” Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Kafka

### ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ

```bash
# Ğ’Ğ¾Ğ¹Ñ‚Ğ¸ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€
docker exec -it kafka bash

# ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ
echo '{"id":"test-1","message":"Hello Kafka"}' | \
  kafka-console-producer \
    --bootstrap-server localhost:9092 \
    --topic logging-events
```

### Ğ§Ñ‚ĞµĞ½Ğ¸Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹

```bash
# Ğ§Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ°
kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic logging-events \
  --from-beginning

# Ğ§Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ¾Ğ²Ñ‹Ğµ
kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic logging-events
```

---

## ğŸ“Š ĞœĞ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Kafka

### Kafka UI

ĞÑ‚ĞºÑ€Ğ¾Ğ¹Ñ‚Ğµ http://localhost:8090

Ğ’Ñ‹ ÑƒĞ²Ğ¸Ğ´Ğ¸Ñ‚Ğµ:
- Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ñ‚Ğ¾Ğ¿Ğ¸ĞºĞ¾Ğ²
- ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹
- Consumer groups
- Brokers
- Partitions

### ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ñ‡ĞµÑ€ĞµĞ· JMX

```bash
# Ğ’ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ JMX Ğ² docker-compose.yml
environment:
  KAFKA_JMX_PORT: 9999
  KAFKA_JMX_HOSTNAME: localhost

ports:
  - "9999:9999"
```

### Consumer Lag

```bash
# ĞŸÑ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ lag consumer group
docker exec kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe \
  --group logging-service-group
```

---

## âš™ï¸ Production Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸

### Ğ ĞµĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ

```yaml
kafka:
  environment:
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
    KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
    KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
```

### Retention

```yaml
kafka:
  environment:
    KAFKA_LOG_RETENTION_HOURS: 168  # 7 Ğ´Ğ½ĞµĞ¹
    KAFKA_LOG_RETENTION_BYTES: 1073741824  # 1 GB
    KAFKA_LOG_SEGMENT_BYTES: 1073741824
```

### Performance

```yaml
kafka:
  environment:
    KAFKA_NUM_NETWORK_THREADS: 8
    KAFKA_NUM_IO_THREADS: 8
    KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
    KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
    KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
```

---

## âœ… Ğ§ĞµĞºĞ»Ğ¸ÑÑ‚

- [ ] Zookeeper Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½
- [ ] Kafka Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½
- [ ] Kafka UI Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½
- [ ] Ğ¢Ğ¾Ğ¿Ğ¸ĞºĞ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ñ‹
- [ ] Producer ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°
- [ ] Consumer ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°
- [ ] Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ñ‹

---

**Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ÑˆĞ°Ğ³:** [09_LOGGING_SERVICE_OVERVIEW.md](09_LOGGING_SERVICE_OVERVIEW.md)
